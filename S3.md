

## Bucket

- Amazon S3 allows people to store objects(files) in "buckets"(directories)

- Buckets must have a **globally unique** name

- Buckets are defined at regional level (your buckets may access by all AWS accounts around the world)

- Naming convention

  - No uppercase
  - No underscore
  - 3-63 characters long
  - Not an IP
  - Must start with lowercase letter or number

- Objects

  - Objects (files) have a key. The key is the **FULL** path:

    <my_bucket>/my_file.txt

    <my_bucket>/my_folder1/another_folder/my_file.txt

  - There's no concept of "directories" with buckets (although the UI will trick you to think otherwise)

  - Just keys with very long names that contains slashes("/")

  - Objects Values are the content of the body:

    - Max size is 5TB
    - If uploading more then 5GB,must use **multi-part upload**

  - Metadata (list of text key /value pairs - system or user metadata)

  - Tags (Unicode key / value pair - up to 10) - useful for security / lifecycle

  - Version ID (if versioning is enable)

## Versioning

You can version your files in AWS S3

It's enable at the bucket level

Same key overwrite will increment the "version":1,2,3

It's best practice to version your buckets

- Protest against unintended deletes (ability to restore a version)
- Easy roll back to previous version

Any file that is not versioned prior to enabling versioning will have version **NULL**

When you delete a file,it does not really delete a file but putting a **delete marker** on it

## Encryption (Important)

4 methods

- SSE-S3: encrypts S3 object using keys handled & managed by AWS
- SSE-KMS: leverage AWS Key Management Service to manage encryption keys
- SSE-C: when you want to manage your own encryption keys
- Client Side Encryption

### SSE-S3

Encryption using keys handled & managed by AWS S3

Object is encrypted server side

AES-256 encryption type

Must set header "x-amz-server-side-encryption":"AES256"

![image-20200402205634107](.\screenshot\image-20200402205634107.png)

## SSE-KMS

encryption using keys handled & managed by KMS

KMS advantages: user control + audit trail

Object is encrypted server side

Must set header "x-amz-server-side-encryption":"aws:kms"

![image-20200402205906898](.\screenshot\image-20200402205906898.png)

**Different from SSE-S3**: using KMS instead of S3 Managed data key

## SEE-C

server-side encryption using data keys full managed by the customer outside of AWS

S3 does not store the encryption key you provide

HTTPS **MUST** be used

encryption key must provided in HTTP headers,for every HTTP request made

![image-20200402210301466](.\screenshot\image-20200402210301466.png)

### Client Side Encryption

Client library such as Amazon S3 Encryption Client

Clients must encrypt data themselves before sending to S3

Clients must decrypt data themselves when retrieving from S3

Customer fully manages the keys and encryption cycle

![image-20200402210551282](.\screenshot\image-20200402210551282.png)

### Encryption in transit (SSL)

AWS S3 exposes:

-  HTTP endpoint: non encrypted
- HTTPS endpoint: encryption in flight

You are free to use the endpoint you want,but HTTPS is recommended

HTTPS is mandatory for SSE-C

Encryption in flight is also called SSL-TLS

## S3 Security & Bucket Policies 

- User based

  **IAM policies** - which API calls should be allowed for a specific user from IAM console

- Resource based

  - **Bucket Policies** - bucket wide rules from S3 console - allows cross account
  - Object Access Control List (ACL) - finer grain
  - Bucket Access Control List (ACL) - less common

### Bucket Policies

- JSON based policies
  - Resources: buckets and objects
  - Actions: Set of API to Allow or Deny
  - Effect: Allow / Deny
  - Principal: The account or user to apply the policies to
- Use S3 bucket for policy to:
  - Grant public access to the bucket
  - Force objects to be encrypted at upload
  - Grant access to another account (Cross Account)

### Other

- Networking:

  Support VPC Endpoints (for instance in VPC without www internet)

- Logging and Audit

  - S3 access logs can be stored in other S3 bucket
  - API calls can be logged in AWS CloudTrail

- User Security

  - MFA (multi factor authentication) can be required in versioned buckets to delete objects
  - Signed URLs: URLs that are valid only for a limited time

## Websites

S3 can host static websites and have them accessible on the www 

The website URL will be:

- <bucket-name>.s3-website-<AWS-region>.amazon.com

  or

- <bucket-name>.s3-website.<AWS-region>.amazon.com

If you get a 403 (Forbidden) error, make sure the bucket policy allows public reads

## CORS

If you request data from another S3 bucket,you need to enable CORS

Cross Origin Resource Sharing allows you to limit the number of websites that can request your files in S3

![image-20200402213813856](.\screenshot\image-20200402213813856.png)

## Consistency Model

- **Read after write** consistency for PUTS of new objects

  -  As soon as an object is written,we can retrieve it

    PUT200 -> GET200

  - This is true,expect if we did a GET before to see if the object existed

    GET404 -> PUT200 -> GET404 ---- eventually consistent

- Eventual Consistency for DELETES and PUTS of existing objects

  - If we read an object after updating,we might the older version

    PUT200- > PUT200 -> GET200 (might be older version)

  - If we delete an object,we might still be able to retrieve it for a short time

    DELETE200 -> GET200

## S3 Tire

- S3 Standard - General

  - High durability 99.999999% of the objects across multiple AZ

  - If you store 10,000,000 objects with S3,you can on average expect incur a loss of a single object once every 1000 years
  - 99.99% Availability over a given year
  - Sustain 2 concurrent facility  failures
  - Use Cases: Big data analytics,mobile & gaming applications,content distribution

- S3 Standard - Infrequent Access (IA)

  - Suitable for data that is less frequently accessed,but requires rapid access when needed
  - High durability (99.99999999%) of objects across multiple AZs
  - 99.9% Availability
  - Low cost compared to S3 Standard
  - Sustain 2 concurrent facility failures
  - Use Cases: As a data store for disaster recovery,backups

- S3 One Zone - Infrequent Access (IA)

  - Same as IA but data is stored in a single AZ
  - High durability (99.99999999%) of objects in a single AZ,data lost when AZ is destroyed
  - 99.5% Availability 
  - Low latency and high throughput performance
  - Support SSL for data at transit and encryption at rest
  - Low cost compared to IA (by 20%)
  - Use Cases: Storing secondary backup copies of on-premise data,or storing data you can recreate

- S3 Intelligent Tiering

  - Same low latency and high throughput performance of S3 Standard
  - Small monthly monitoring and auto-tiering fee
  - Automatically moves objects between tow access tiers based on changing access patterns
  - Designed for durability of 99.999999999% of objects across multiple AZs
  - Resilient against events that impact an entire AZ
  - Designed for 99.99 availability over a given year

- Amazon Glacier

  - Low cost object storage meant for archiving / backup
  - Data is retained for the longer term (10s of year)
  - Alternative to on-premise magnetic tape storage
  - Average annual durability is 99.999999999%
  - Cost per storage per month ($0.004/GB) + retrieval cost
  - Each item in Glacier is called "Archive" (up to 40TB)
  - Archives are stored in "Vaults"
  - 3 retrieval options:
    - Expedited (1 to 5 minutes)
    - Standard (3 to 5 hours)
    - Bulk (5 to 12 hours)
    - Minimum storage duration of 90 days

- Amazon Glacier Deep Archive
  - for long term storage 
  - cheaper
  - retrieval options:
    - Standard (12 hours)
    - Bulk (48 hours)
    - Minimum storage duration of 180 days

## S3 Lifecycle Policies

![image-20200406212917263](.\screenshot\image-20200406212917263.png)

- Transition actions: It defines when objects are transitioned to another storage class
  - Move objects to Standard IA class 60 days after creation
  - Move to Glacier for archiving after 6 months
- Expiration actions: configure objects to expire (delete) after some time
  - Access log files can be set to delete after a 365 days
  - <u>Can be used to delete old versions of files(if versioning is enabled)</u>
  - Can be used to delete incomplete multi-part uploads
- Rules can be created for a certain prefix (ex - s3://mybucket/mp3/*)
- Rules can be created for a certain objects tags (ex - Department: Finance)

## S3 Performance

- S3 automatically scales to high request rates,latency 100-200 ms

- Your application can archive at least <u>3500 PUT/COPY/POST/DELETE and 5500 GET/HEAD requests per second **per prefix** in a bucket</u>

- There are no limits to the number of prefixes in a bucket

  Example: **(prefix => from "bucket" to "file")**

  - bucket/folder1/sub1/file => /folder/sub1/
  - bucket/folder1/sub2/file => /folder/sub2/
  - bucket/1/file => /1/
  - bucket/2/file => /2/

- If you spread reads across all four prefixes evenly,you can achieve 22000 requests per second of GET and HEAD

### KMS Limitation

- If you use SSE-KMS,you may be impacted by KMS limits
- When you upload,it calls the **GenerateDataKey** KMS API
- When you download,it calls the **Decrypt** KMS API
- Count towards the KMS quota per second (5500,10000,30000 req/s based on region)
- As of today,you cannot request a quota increase for KMS
- ![image-20200406215032785](.\screenshot\image-20200406215032785.png)

## How to Optimize

- Multi-Part upload

  - Recommended for files > 100 MB,must use for files > 50 GB
  - Can help parallelize uploads (speed up transfers)
  - ![image-20200406215323470](.\screenshot\image-20200406215323470.png)

- S3 Transfer Acceleration (upload only)

  - Increase transfer speed by transferring file to an AWS edge location which will forward the data to the S3 bucket in the target region
  - Compatible with multi-part upload
  - ![image-20200406215445270](.\screenshot\image-20200406215445270.png)

- S3 Byte-Range Fetches

  - Parallelize GETs by requesting specific byte ranges
  - Better resilience in case of failures
  - <u>can be used to speed up downloads</u>
  - <u>can be used to retrieve only partial data (for example the head of a file)</u>
  - ![image-20200406215953526](.\screenshot\image-20200406215953526.png)
  - ![image-20200406215958569](.\screenshot\image-20200406215958569.png)

  ## S3 Select & Glacier Select

  - Retrieve less data using SQL by performing **sever side filtering**
  - Can filter by rows & columns (simple SQL statements)
  - Less network transfer,less CPU cost client-side
  - ![image-20200406220240382](.\screenshot\image-20200406220240382.png)

  ## Athena

  **Serverless** service to perform analytics direcylt against S3 files

  Uses SQL language to query the files

  Has a JDBC/ODBC driver

  Charged per query and amount of data scanned

  Supports CSV,JSON,ORC,AVRO,and Parquet (built on Presto)

  Use cases: BA,reporting,analyze & query VPC Flow Logs,ELB Logs, CloudTrail trails 

  **Exam tip: Analyze data directly on S3 => use Athena**

  ## S3 Object Lock & Glacier Vault Lock

  - S3 object Lock

    - Adopt a WORM (Write Once Read Many) model
    - Block an object version deletion for a specified amount of time

  - Glacier Vault Lock

    - Adopt a WORM (Write Once Read Many) model
    - Lock the policy for future edit(can no longer be changed)
    - Helpful for compliance and data retention

  - ![image-20200406221614095](.\screenshot\image-20200406221614095.png)

  

  

  

  
